{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bidirectional_GRU_Glove_840B.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "tqRkQkb5CQ62",
        "colab_type": "code",
        "outputId": "06d729e6-5cfa-4cb0-9c45-c5a0d47bc629",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "cell_type": "code",
      "source": [
        "#Download Glove twitter embeddings\n",
        "!wget http://nlp.stanford.edu/data/glove.840B.300d.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-11-22 04:17:06--  http://nlp.stanford.edu/data/glove.840B.300d.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.840B.300d.zip [following]\n",
            "--2018-11-22 04:17:06--  https://nlp.stanford.edu/data/glove.840B.300d.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2176768927 (2.0G) [application/zip]\n",
            "Saving to: ‘glove.840B.300d.zip’\n",
            "\n",
            "glove.840B.300d.zip 100%[===================>]   2.03G  14.0MB/s    in 2m 10s  \n",
            "\n",
            "2018-11-22 04:19:16 (16.0 MB/s) - ‘glove.840B.300d.zip’ saved [2176768927/2176768927]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "S50yjMiYCuS_",
        "colab_type": "code",
        "outputId": "e981d084-f4f8-4414-dd14-f2685910d367",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "!unzip glove.840B.300d.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.840B.300d.zip\n",
            "  inflating: glove.840B.300d.txt     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EuiEKHdZDYu7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm glove.840B.300d.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gH1VxrVgEJdr",
        "colab_type": "code",
        "outputId": "35b686ea-a9d1-496b-eb09-b300e27f2789",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "cell_type": "code",
      "source": [
        "!ls -lrt"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 5513912\n",
            "-rw-rw-r-- 1 root root 5646236541 Oct 24  2015 glove.840B.300d.txt\n",
            "drwxr-xr-x 2 root root       4096 Nov 20 18:17 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8XN_YBxZXPUm",
        "colab_type": "code",
        "outputId": "19feb332-dec7-468a-e55b-2c601c044e03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install googledrivedownloader"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting googledrivedownloader\n",
            "  Downloading https://files.pythonhosted.org/packages/7e/41/d59b2a5fcc7afeb40f23091694bd6e6a63ad118c93f834353ee5100285d5/googledrivedownloader-0.3-py2.py3-none-any.whl\n",
            "Installing collected packages: googledrivedownloader\n",
            "Successfully installed googledrivedownloader-0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "u5eYBsEQXMIQ",
        "colab_type": "code",
        "outputId": "5acae2b3-d133-45f6-ba98-53d60770cefd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "cell_type": "code",
      "source": [
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "\n",
        "ids =[\"1EO59IOOCVcqKymPzTOVHKxTmIjEKEfW2\", \"1pSY29XeBuodiIZdtGDtq52MZsAJTAKdo\", \"1Jt7Wr3RUQRnLD0AuirxPCxjkljfumPLw\"]\n",
        "\n",
        "file_names = [\"test.csv\",\"train.csv\",\"sample_submission.csv\"]\n",
        "for i in range(len(ids)):\n",
        "  a = gdd.download_file_from_google_drive(file_id= ids[i],\n",
        "                                      dest_path=\"./\"+file_names[i],\n",
        "                                      unzip=False)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 1EO59IOOCVcqKymPzTOVHKxTmIjEKEfW2 into ./test.csv... Done.\n",
            "Downloading 1pSY29XeBuodiIZdtGDtq52MZsAJTAKdo into ./train.csv... Done.\n",
            "Downloading 1Jt7Wr3RUQRnLD0AuirxPCxjkljfumPLw into ./sample_submission.csv... Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "M6rDqcu7EVN1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "d4c0321e-5973-4edb-e558-65f06b797120"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from keras.layers import Dense,Input,LSTM,Bidirectional,Activation,Conv1D,GRU\n",
        "from keras.callbacks import Callback\n",
        "from keras.layers import Dropout,Embedding,GlobalMaxPooling1D, MaxPooling1D, Add, Flatten\n",
        "from keras.preprocessing import text, sequence\n",
        "from keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
        "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "AobxpcYSYgNl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(\"train.csv\", header =0)\n",
        "test = pd.read_csv(\"test.csv\", header = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2BjBF5Q_ZI4w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train[\"comment_text\"].fillna(\"dummytext\")\n",
        "test[\"comment_text\"].fillna(\"dummytext\")\n",
        "X_train = train[\"comment_text\"].str.lower()\n",
        "X_test = test[\"comment_text\"].str.lower()\n",
        "Y_train = train[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tANvMapYZyIc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Parameters\n",
        "embedding_size = 300\n",
        "maxlen = 150\n",
        "max_vocab_size = 100000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qz2Ue2f2agpE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tokenizer = text.Tokenizer(num_words = max_vocab_size, lower = False)  \n",
        "# num_words - will consider only top max_vocab_size words based on frequency count\n",
        "# So, when we do texts_to_sequences, the max value will be 100,000. \n",
        "# But, tokinzer on its own will contain word and indices for all the words in the corpus.\n",
        "\n",
        "tokenizer.fit_on_texts(list(X_train) + list(X_test))\n",
        "#Its not necessary to fit on both the train and test. If we do that, we take into account the top words of test set as well \n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DUxZZ5RdfOCs",
        "colab_type": "code",
        "outputId": "5dc36442-4276-4a2a-ccb3-c27bcc9914d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "glove_embeddings = {}\n",
        "\n",
        "with open(\"glove.840B.300d.txt\", encoding= \"utf8\" ) as f:\n",
        "  for line in f:\n",
        "    words_vector = line.rstrip().rsplit(\" \")\n",
        "    word = words_vector[0]\n",
        "    vector = np.asarray(words_vector[1:], dtype= 'float32')\n",
        "    glove_embeddings[word] = vector\n",
        "\n",
        "print(\"There are: \"+str(len(glove_embeddings))+\" glove word embeddings\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are: 2196016 glove word embeddings\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "37zJWOv-r5Il",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "max_word_index_tokenizer = len(tokenizer.word_index)\n",
        "num_words = min(max_vocab_size, max_word_index_tokenizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pzq2FIAhsmcz",
        "colab_type": "code",
        "outputId": "fe274e05-2ab1-4dc3-a150-de9dd4990c19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "oov_count = 0\n",
        "embedding_matrix = np.ones((num_words, embedding_size))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "  if i>= max_vocab_size:\n",
        "    continue\n",
        "  embedding_vector = glove_embeddings.get(word)\n",
        "  \n",
        "  if embedding_vector is not None:\n",
        "    embedding_matrix[i] = embedding_vector \n",
        "   \n",
        "  else:\n",
        "    oov_count+=1\n",
        "   \n",
        "  \n",
        "print(\"There are \"+str(oov_count)+\" missing glove word embeddings\") \n",
        "    \n",
        "  "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 26633 missing glove word embeddings\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fYHvJynlt1TU",
        "colab_type": "code",
        "outputId": "4d5864c5-08be-4ef2-bfa1-7c8a49910a78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "cell_type": "code",
      "source": [
        "sequence_input = Input(shape = (maxlen,)) # Every senetence will have a maxlength of 150.\n",
        "x = Embedding(input_dim = max_vocab_size, output_dim = embedding_size, trainable = False, weights = [embedding_matrix]) (sequence_input)\n",
        "x = Bidirectional(GRU(128, return_sequences=True)) (x)\n",
        "# 128 is the number of hidden units in each GRU cell. \n",
        "# return_sequences makes the output of each GRU cell as the input to next cell. \n",
        "# We have 128 neurons in each GRU cell. Since it is bidirectional GRU, the forward and the backward pass\n",
        "# are concatenated and we get 256 neuron ouput from each GRU cell.\n",
        "# Since we have 150 as max sequence length, the dimension after this cell is (150, 256)\n",
        "\n",
        "x = GlobalMaxPooling1D()(x)\n",
        "predictions = Dense(6, activation=\"sigmoid\")(x)\n",
        "\n",
        "model = Model(sequence_input, predictions)\n",
        "model.summary()\n",
        "model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 150)               0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 150, 300)          30000000  \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 150, 256)          329472    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6)                 1542      \n",
            "=================================================================\n",
            "Total params: 30,331,014\n",
            "Trainable params: 331,014\n",
            "Non-trainable params: 30,000,000\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6WNJb6cp5Flm",
        "colab_type": "code",
        "outputId": "89e42d74-a3e0-45ef-8c1e-f2464e2b77f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "epochs = 4\n",
        "X_train_sub, X_val_sub, Y_train_sub, Y_val_sub = train_test_split(X_train, Y_train, train_size=0.9, random_state=123)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "k_UIzY9a9KPc",
        "colab_type": "code",
        "outputId": "8650368f-a037-44de-b7bd-582d7e347a4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "cell_type": "code",
      "source": [
        "file_path=\"glove_weights_base.best.hdf5\"\n",
        "checkpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "\n",
        "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5)\n",
        "\n",
        "\n",
        "callbacks_list = [checkpoint, early] #early\n",
        "model.fit(X_train_sub, Y_train_sub, batch_size=batch_size, epochs=epochs, validation_data=(X_val_sub, Y_val_sub), callbacks=callbacks_list)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 143613 samples, validate on 15958 samples\n",
            "Epoch 1/4\n",
            "143613/143613 [==============================] - 796s 6ms/step - loss: 0.0534 - acc: 0.9809 - val_loss: 0.0394 - val_acc: 0.9847\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.03938, saving model to glove_weights_base.best.hdf5\n",
            "Epoch 2/4\n",
            "143613/143613 [==============================] - 774s 5ms/step - loss: 0.0410 - acc: 0.9841 - val_loss: 0.0378 - val_acc: 0.9852\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.03938 to 0.03775, saving model to glove_weights_base.best.hdf5\n",
            "Epoch 3/4\n",
            "143613/143613 [==============================] - 777s 5ms/step - loss: 0.0382 - acc: 0.9850 - val_loss: 0.0380 - val_acc: 0.9848\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.03775\n",
            "Epoch 4/4\n",
            "143613/143613 [==============================] - 769s 5ms/step - loss: 0.0355 - acc: 0.9859 - val_loss: 0.0368 - val_acc: 0.9851\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.03775 to 0.03683, saving model to glove_weights_base.best.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6247304dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "mqVp_zWE9e_-",
        "colab_type": "code",
        "outputId": "26551374-4c9c-43b3-972e-99c4c69b4e40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "model.load_weights(file_path)\n",
        "test_predictions = model.predict(X_test,batch_size=1024,verbose=1)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "153164/153164 [==============================] - 47s 304us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iWa5zAg1IYoB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "submission = pd.read_csv('sample_submission.csv')\n",
        "submission[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]] = test_predictions\n",
        "submission.to_csv('biGRU_Glove_840B.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0sAJ8Ca9JeXo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(\"biGRU_Glove_840B.csv\") "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yeF27YYeJioI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#0.9826 Private  0.9843 Public"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qS859IO83mJe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
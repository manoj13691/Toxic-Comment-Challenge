{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bidirectional_GRU_Fasttext.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "tqRkQkb5CQ62",
        "colab_type": "code",
        "outputId": "6853181e-b7c3-4d47-fe40-afdfdadcb916",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        }
      },
      "cell_type": "code",
      "source": [
        "#Download Fasttext embeddings\n",
        "!wget https://s3-us-west-1.amazonaws.com/fasttext-vectors/crawl-300d-2M-subword.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-11-22 06:06:36--  https://s3-us-west-1.amazonaws.com/fasttext-vectors/crawl-300d-2M-subword.zip\n",
            "Resolving s3-us-west-1.amazonaws.com (s3-us-west-1.amazonaws.com)... 52.219.116.9\n",
            "Connecting to s3-us-west-1.amazonaws.com (s3-us-west-1.amazonaws.com)|52.219.116.9|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5828358084 (5.4G) [application/zip]\n",
            "Saving to: ‘crawl-300d-2M-subword.zip’\n",
            "\n",
            "crawl-300d-2M-subwo 100%[===================>]   5.43G  25.1MB/s    in 2m 41s  \n",
            "\n",
            "2018-11-22 06:09:17 (34.5 MB/s) - ‘crawl-300d-2M-subword.zip’ saved [5828358084/5828358084]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "S50yjMiYCuS_",
        "colab_type": "code",
        "outputId": "bdfc65d0-23d3-407a-9a33-d90052a449a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "cell_type": "code",
      "source": [
        "!unzip crawl-300d-2M-subword.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  crawl-300d-2M-subword.zip\n",
            "  inflating: crawl-300d-2M-subword.vec  \n",
            "  inflating: crawl-300d-2M-subword.bin  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EuiEKHdZDYu7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm crawl-300d-2M-subword.zip glove.840B.300d.txt crawl-300d-2M-subword.bin glove_weights_base.best.hdf5 biGRU_Glove_840B.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gH1VxrVgEJdr",
        "colab_type": "code",
        "outputId": "16870b6b-6082-44a3-88b5-7fc8ae880d62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        }
      },
      "cell_type": "code",
      "source": [
        "!ls -lrt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 4546472\n",
            "-rw-r--r-- 1 root root 4520128711 Aug 22 20:30 crawl-300d-2M-subword.vec\n",
            "drwxr-xr-x 2 root root       4096 Nov 20 18:17 sample_data\n",
            "-rw-r--r-- 1 root root   60354593 Nov 22 04:21 test.csv\n",
            "-rw-r--r-- 1 root root   68802655 Nov 22 04:21 train.csv\n",
            "-rw-r--r-- 1 root root    6279782 Nov 22 04:21 sample_submission.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8XN_YBxZXPUm",
        "colab_type": "code",
        "outputId": "19feb332-dec7-468a-e55b-2c601c044e03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install googledrivedownloader"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting googledrivedownloader\n",
            "  Downloading https://files.pythonhosted.org/packages/7e/41/d59b2a5fcc7afeb40f23091694bd6e6a63ad118c93f834353ee5100285d5/googledrivedownloader-0.3-py2.py3-none-any.whl\n",
            "Installing collected packages: googledrivedownloader\n",
            "Successfully installed googledrivedownloader-0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "u5eYBsEQXMIQ",
        "colab_type": "code",
        "outputId": "5acae2b3-d133-45f6-ba98-53d60770cefd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "cell_type": "code",
      "source": [
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "\n",
        "ids =[\"1EO59IOOCVcqKymPzTOVHKxTmIjEKEfW2\", \"1pSY29XeBuodiIZdtGDtq52MZsAJTAKdo\", \"1Jt7Wr3RUQRnLD0AuirxPCxjkljfumPLw\"]\n",
        "\n",
        "file_names = [\"test.csv\",\"train.csv\",\"sample_submission.csv\"]\n",
        "for i in range(len(ids)):\n",
        "  a = gdd.download_file_from_google_drive(file_id= ids[i],\n",
        "                                      dest_path=\"./\"+file_names[i],\n",
        "                                      unzip=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 1EO59IOOCVcqKymPzTOVHKxTmIjEKEfW2 into ./test.csv... Done.\n",
            "Downloading 1pSY29XeBuodiIZdtGDtq52MZsAJTAKdo into ./train.csv... Done.\n",
            "Downloading 1Jt7Wr3RUQRnLD0AuirxPCxjkljfumPLw into ./sample_submission.csv... Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "M6rDqcu7EVN1",
        "colab_type": "code",
        "outputId": "e70f47ea-91a8-4e82-a5b8-c966d7a758ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from keras.layers import Dense,Input,LSTM,Bidirectional,Activation,Conv1D,GRU\n",
        "from keras.callbacks import Callback\n",
        "from keras.layers import Dropout,Embedding,GlobalMaxPooling1D, MaxPooling1D, Add, Flatten\n",
        "from keras.preprocessing import text, sequence\n",
        "from keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
        "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "AobxpcYSYgNl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(\"train.csv\", header =0)\n",
        "test = pd.read_csv(\"test.csv\", header = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2BjBF5Q_ZI4w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train[\"comment_text\"].fillna(\"dummytext\")\n",
        "test[\"comment_text\"].fillna(\"dummytext\")\n",
        "X_train = train[\"comment_text\"].str.lower()\n",
        "X_test = test[\"comment_text\"].str.lower()\n",
        "Y_train = train[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tANvMapYZyIc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Parameters\n",
        "embedding_size = 300\n",
        "maxlen = 150\n",
        "max_vocab_size = 100000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qz2Ue2f2agpE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tokenizer = text.Tokenizer(num_words = max_vocab_size, lower = False)  \n",
        "# num_words - will consider only top max_vocab_size words based on frequency count\n",
        "# So, when we do texts_to_sequences, the max value will be 100,000. \n",
        "# But, tokinzer on its own will contain word and indices for all the words in the corpus.\n",
        "\n",
        "tokenizer.fit_on_texts(list(X_train) + list(X_test))\n",
        "#Its not necessary to fit on both the train and test. If we do that, we take into account the top words of test set as well \n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DUxZZ5RdfOCs",
        "colab_type": "code",
        "outputId": "ae945caf-d859-4d49-83c2-7ef94ab0716d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "glove_embeddings = {}\n",
        "\n",
        "with open(\"crawl-300d-2M-subword.vec\", encoding= \"utf8\" ) as f:\n",
        "  for line in f:\n",
        "    words_vector = line.rstrip().rsplit(\" \")\n",
        "    word = words_vector[0]\n",
        "    vector = np.asarray(words_vector[1:], dtype= 'float32')\n",
        "    glove_embeddings[word] = vector\n",
        "\n",
        "print(\"There are: \"+str(len(glove_embeddings))+\" fasttext word embeddings\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are: 2000000 fasttext word embeddings\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "37zJWOv-r5Il",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "max_word_index_tokenizer = len(tokenizer.word_index)\n",
        "num_words = min(max_vocab_size, max_word_index_tokenizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pzq2FIAhsmcz",
        "colab_type": "code",
        "outputId": "c94fee09-95a5-4c38-cad8-565cf8c2698c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "oov_count = 0\n",
        "embedding_matrix = np.ones((num_words, embedding_size))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "  if i>= max_vocab_size:\n",
        "    continue\n",
        "  embedding_vector = glove_embeddings.get(word)\n",
        "  \n",
        "  if embedding_vector is not None:\n",
        "    embedding_matrix[i] = embedding_vector \n",
        "   \n",
        "  else:\n",
        "    oov_count+=1\n",
        "   \n",
        "  \n",
        "print(\"There are \"+str(oov_count)+\" missing fasttext word embeddings\") \n",
        "    \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 25989 missing fasttext word embeddings\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fYHvJynlt1TU",
        "colab_type": "code",
        "outputId": "47d21951-d348-4ccd-c3a3-dc7d9b3eb485",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "cell_type": "code",
      "source": [
        "sequence_input = Input(shape = (maxlen,)) # Every senetence will have a maxlength of 150.\n",
        "x = Embedding(input_dim = max_vocab_size, output_dim = embedding_size, trainable = False, weights = [embedding_matrix]) (sequence_input)\n",
        "x = Bidirectional(GRU(128, return_sequences=True)) (x)\n",
        "# 128 is the number of hidden units in each GRU cell. \n",
        "# return_sequences makes the output of each GRU cell as the input to next cell. \n",
        "# We have 128 neurons in each GRU cell. Since it is bidirectional GRU, the forward and the backward pass\n",
        "# are concatenated and we get 256 neuron ouput from each GRU cell.\n",
        "# Since we have 150 as max sequence length, the dimension after this cell is (150, 256)\n",
        "\n",
        "x = GlobalMaxPooling1D()(x)\n",
        "predictions = Dense(6, activation=\"sigmoid\")(x)\n",
        "\n",
        "model = Model(sequence_input, predictions)\n",
        "model.summary()\n",
        "model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 150)               0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 150, 300)          30000000  \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 150, 256)          329472    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6)                 1542      \n",
            "=================================================================\n",
            "Total params: 30,331,014\n",
            "Trainable params: 331,014\n",
            "Non-trainable params: 30,000,000\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6WNJb6cp5Flm",
        "colab_type": "code",
        "outputId": "4e9929fe-e8d4-497a-e063-2718a52c934a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "epochs = 4\n",
        "X_train_sub, X_val_sub, Y_train_sub, Y_val_sub = train_test_split(X_train, Y_train, train_size=0.9, random_state=123)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "k_UIzY9a9KPc",
        "colab_type": "code",
        "outputId": "c570e990-fd46-4ba0-c10c-a6b75e479367",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "cell_type": "code",
      "source": [
        "file_path=\"glove_weights_base.best.hdf5\"\n",
        "checkpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "\n",
        "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5)\n",
        "\n",
        "\n",
        "callbacks_list = [checkpoint, early] #early\n",
        "model.fit(X_train_sub, Y_train_sub, batch_size=batch_size, epochs=epochs, validation_data=(X_val_sub, Y_val_sub), callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 143613 samples, validate on 15958 samples\n",
            "Epoch 1/4\n",
            "143613/143613 [==============================] - 801s 6ms/step - loss: 0.0712 - acc: 0.9759 - val_loss: 0.0470 - val_acc: 0.9822\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.04702, saving model to glove_weights_base.best.hdf5\n",
            "Epoch 2/4\n",
            "143613/143613 [==============================] - 788s 5ms/step - loss: 0.0496 - acc: 0.9814 - val_loss: 0.0425 - val_acc: 0.9836\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.04702 to 0.04248, saving model to glove_weights_base.best.hdf5\n",
            "Epoch 3/4\n",
            "143613/143613 [==============================] - 785s 5ms/step - loss: 0.0449 - acc: 0.9829 - val_loss: 0.0422 - val_acc: 0.9838\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.04248 to 0.04218, saving model to glove_weights_base.best.hdf5\n",
            "Epoch 4/4\n",
            "143613/143613 [==============================] - 783s 5ms/step - loss: 0.0423 - acc: 0.9836 - val_loss: 0.0392 - val_acc: 0.9850\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.04218 to 0.03924, saving model to glove_weights_base.best.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe5a5888470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "mqVp_zWE9e_-",
        "colab_type": "code",
        "outputId": "22819b95-8845-4222-9c91-b28d314f4d04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "model.load_weights(file_path)\n",
        "test_predictions = model.predict(X_test,batch_size=1024,verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "153164/153164 [==============================] - 47s 309us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iWa5zAg1IYoB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "submission = pd.read_csv('sample_submission.csv')\n",
        "submission[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]] = test_predictions\n",
        "submission.to_csv('biGRU_fasttext.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0sAJ8Ca9JeXo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(\"biGRU_fasttext.csv\") "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yeF27YYeJioI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#0.9826 Private  0.9843 Public"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qS859IO83mJe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
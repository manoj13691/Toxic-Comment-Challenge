{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.util import ngrams\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "filename = \"train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(filename, header=0)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 8)\n",
      "(1000, 8)\n"
     ]
    }
   ],
   "source": [
    "data[\"comment_text\"] = data[\"comment_text\"].fillna(\"_na_\").values\n",
    "#data[\"comment_text\"]= data[\"comment_text\"].str.replace(\"\\n\", \" \")\n",
    "print(data.shape)\n",
    "data.head(10)\n",
    "#Take 10,000 samples. \n",
    "data = data.head(1000)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import pandas as pd\n",
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_sentences(text):\n",
    "    stop_words = set(stopwords.words('english'))  \n",
    "    word_tokens = tokenizer.tokenize(text)\n",
    "    word_tokens = [ps.stem(w) for w in word_tokens]\n",
    "    filtered_sentence = [w.lower() for w in word_tokens if not w in stop_words and not w.isdigit()]\n",
    "    return \" \".join(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>explan whi edit made usernam hardcor metallica...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>d aww he match thi background colour i seeming...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>hey man i realli tri edit war it thi guy const...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>i make ani real suggest improv i wonder sectio...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>sir hero ani chanc rememb page</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  explan whi edit made usernam hardcor metallica...      0   \n",
       "1  000103f0d9cfb60f  d aww he match thi background colour i seeming...      0   \n",
       "2  000113f07ec002fd  hey man i realli tri edit war it thi guy const...      0   \n",
       "3  0001b41b1c6bb37e  i make ani real suggest improv i wonder sectio...      0   \n",
       "4  0001d958c54c6e35                     sir hero ani chanc rememb page      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_comments = list(data[\"comment_text\"])\n",
    "\n",
    "filtered_sentences = []\n",
    "for comment in list_of_comments:\n",
    "    filtered_sentences.append(filter_sentences(comment))\n",
    "\n",
    "data[\"comment_text\"] = pd.Series(filtered_sentences)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_words = dict()\n",
    "all_comments = list(data[\"comment_text\"])\n",
    "# Get the number of unique words\n",
    "for comment in all_comments:\n",
    "    word_tokens = tokenizer.tokenize(comment)\n",
    "    for word in word_tokens:\n",
    "        if word not in unique_words:\n",
    "            unique_words[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7088"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_bigrams = {}\n",
    "for comment in all_comments:\n",
    "    token = word_tokenize(comment)\n",
    "    bigrams = list(ngrams(token,2))\n",
    "    for bigram_pair in bigrams:\n",
    "        if bigram_pair not in all_bigrams:\n",
    "            all_bigrams[bigram_pair] = 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32323"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are: 105 samples for label: toxic\n",
      "There are: 9 samples for label: severe_toxic\n",
      "There are: 49 samples for label: obscene\n",
      "There are: 4 samples for label: threat\n",
      "There are: 54 samples for label: insult\n",
      "There are: 9 samples for label: identity_hate\n"
     ]
    }
   ],
   "source": [
    "# Class distribution\n",
    "labels = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "for label in labels:\n",
    "    count = sum(data[label]==1)\n",
    "    print(\"There are: \"+str(count)+\" samples for label: \"+label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sample code to convert list into Dataframe\n",
    "col_names = [\"a\", \"b\", \"c\"]\n",
    "data_new = [[1,1,1], [0,0,0], [1,0,1]]\n",
    "df = pd.DataFrame(data_new, columns = col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_bigrams_list = [bigram_pair[0]+\":\"+bigram_pair[1] for bigram_pair in all_bigrams.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_names  = all_bigrams_list + labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0001d958c54c6e35', 'sir hero ani chanc rememb page', 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "for index in range(len(data)):\n",
    "    print(list(data.iloc[index+4]))\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_data = []\n",
    "for record_index in range(len(data)):\n",
    "    new_record_for_final_data = []\n",
    "    current_record = data.iloc[record_index]\n",
    "    \n",
    "    #Current_record is a data frame\n",
    "    comment = current_record[\"comment_text\"]\n",
    "    \n",
    "    token = word_tokenize(comment)\n",
    "    bigrams = list(ngrams(token,2))\n",
    "    all_bigrams_dict = {}\n",
    "    \n",
    "    for bigram_pair in bigrams:\n",
    "        modified_bigram_pair = bigram_pair[0]+\":\"+bigram_pair[1] #Same way as in all_bigrams_list\n",
    "        if modified_bigram_pair not in all_bigrams:\n",
    "            all_bigrams_dict[modified_bigram_pair] = 1\n",
    "        else:\n",
    "            all_bigrams_dict[modified_bigram_pair] +=1\n",
    "    \n",
    "    # Now we have bigram count as a dictionary for this record.\n",
    "    # We have to check this against all the bi-grams of the corpus stored in all_bigrams_list\n",
    "    for i in range(len(all_bigrams_list)):\n",
    "        if all_bigrams_list[i] not in all_bigrams_dict:\n",
    "            new_record_for_final_data.append(0)\n",
    "        else:\n",
    "            new_record_for_final_data.append(all_bigrams_dict[all_bigrams_list[i]])\n",
    "    \n",
    "    \n",
    "    for cur_label in labels:\n",
    "        new_record_for_final_data.append(current_record[cur_label])\n",
    "    \n",
    "    if len(new_record_for_final_data)!=len(col_names):\n",
    "        print(\"Error: This should not happen\")\n",
    "        \n",
    "    else:\n",
    "        final_data.append(new_record_for_final_data)\n",
    "        \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(final_data, columns = col_names)\n",
    "df.to_csv(\"final_data_1k.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

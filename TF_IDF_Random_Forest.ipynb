{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "train_file = \"train.csv\"\n",
    "test_file = \"test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(train_file, header=0)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of features after applying TF-IDF are:\n",
      "74583\n",
      "The shape of the data is:\n",
      "(159571, 74583)\n",
      "Ten sample features are:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '0000',\n",
       " '00000',\n",
       " '000000',\n",
       " '0000z',\n",
       " '0001',\n",
       " '0003',\n",
       " '000_bucks',\n",
       " '000ft']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# https://stackoverflow.com/questions/27697766/understanding-min-df-and-max-df-in-scikit-countvectorizer\n",
    "# Above reference is for understanding the parameters of tf-idf.\n",
    "\n",
    "tf = TfidfVectorizer(analyzer='word',lowercase=True, min_df = 2,max_df = 0.9,\n",
    "                     strip_accents='unicode', stop_words = 'english', sublinear_tf=1)\n",
    "\n",
    "X =  tf.fit_transform(data[\"comment_text\"])\n",
    "print(\"The number of features after applying TF-IDF are:\")\n",
    "print(len(tf.get_feature_names()))\n",
    "print(\"The shape of the data is:\")\n",
    "print(X.shape)\n",
    "print(\"Ten sample features are:\")\n",
    "tf.get_feature_names()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>153159</th>\n",
       "      <td>fffcd0960ee309b5</td>\n",
       "      <td>. \\n i totally agree, this stuff is nothing bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153160</th>\n",
       "      <td>fffd7a9a6eb32c16</td>\n",
       "      <td>== Throw from out field to home plate. == \\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153161</th>\n",
       "      <td>fffda9e8d6fafa9e</td>\n",
       "      <td>\" \\n\\n == Okinotorishima categories == \\n\\n I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153162</th>\n",
       "      <td>fffe8f1340a79fc2</td>\n",
       "      <td>\" \\n\\n == \"\"One of the founding nations of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153163</th>\n",
       "      <td>ffffce3fb183ee80</td>\n",
       "      <td>\" \\n :::Stop already. Your bullshit is not wel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text\n",
       "153159  fffcd0960ee309b5  . \\n i totally agree, this stuff is nothing bu...\n",
       "153160  fffd7a9a6eb32c16  == Throw from out field to home plate. == \\n\\n...\n",
       "153161  fffda9e8d6fafa9e  \" \\n\\n == Okinotorishima categories == \\n\\n I ...\n",
       "153162  fffe8f1340a79fc2  \" \\n\\n == \"\"One of the founding nations of the...\n",
       "153163  ffffce3fb183ee80  \" \\n :::Stop already. Your bullshit is not wel..."
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the test file\n",
    "test_data = pd.read_csv(test_file)\n",
    "test_data.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153164, 74583)\n"
     ]
    }
   ],
   "source": [
    "X_test = tf.transform(test_data[\"comment_text\"])\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss: 0.11185005179726798\n",
      "Accuracy: 95.97\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[144275,      2],\n",
       "       [  6434,   8860]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions for toxic  using Random Forest\n",
    "clf = RandomForestClassifier(max_depth=150, n_estimators=100)\n",
    "toxic_labels = list(data[\"toxic\"])\n",
    "clf.fit(X, toxic_labels)\n",
    "ans_probs = clf.predict_proba(X)\n",
    "predictions = clf.predict(X)\n",
    "print(\"Log Loss: \"+str(log_loss(toxic_labels, ans_probs)))\n",
    "accuracy = round(accuracy_score(toxic_labels, predictions) *100,2)\n",
    "print(\"Accuracy: \"+str(accuracy))\n",
    "confusion_matrix(toxic_labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205 0.22947222656189137\n",
      "27 0.17834616234619227\n",
      "38 0.20363420516848946\n",
      "89 0.21413990924274262\n",
      "closure 0.2487963967573361\n",
      "dolls 0.28749813675315267\n",
      "don 0.0914176988445954\n",
      "edits 0.11758377204966428\n",
      "explanation 0.16556591073812327\n",
      "fac 0.21480258987499007\n",
      "fan 0.1841914893111529\n",
      "gas 0.22059674408811816\n",
      "hardcore 0.2432209231302952\n",
      "just 0.08624045494546462\n",
      "metallica 0.2791738288407949\n",
      "new 0.11554577850801136\n",
      "page 0.07950718847788701\n",
      "remove 0.1320049003396883\n",
      "retired 0.22073355658683494\n",
      "reverted 0.1423831296890881\n",
      "talk 0.08044249121071409\n",
      "template 0.15023574657404387\n",
      "username 0.1694647006622534\n",
      "vandalisms 0.2762286662160805\n",
      "voted 0.21349206599775641\n",
      "weren 0.20067679562710994\n",
      "york 0.1865334584329208\n"
     ]
    }
   ],
   "source": [
    "doc = 0\n",
    "feature_names = tf.get_feature_names()\n",
    "feature_index = X[doc,:].nonzero()[1]\n",
    "tfidf_scores = zip(feature_index, [X[doc, x] for x in feature_index])\n",
    "for w, s in [(feature_names[i], s) for (i, s) in tfidf_scores]:\n",
    "    print(w, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_test = clf.predict_proba(X_test)\n",
    "\n",
    "test_data[\"toxic\"] = pd.Series(toxic_test[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss: 0.013691943145166004\n",
      "Accuracy: 99.39\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[157974,      2],\n",
       "       [   972,    623]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions for severe_toxic using Random Forest\n",
    "clf = RandomForestClassifier(max_depth=150, n_estimators=100)\n",
    "severe_toxic_labels = list(data[\"severe_toxic\"])\n",
    "clf.fit(X, severe_toxic_labels)\n",
    "ans_probs = clf.predict_proba(X)\n",
    "predictions = clf.predict(X)\n",
    "print(\"Log Loss: \"+str(log_loss(severe_toxic_labels, ans_probs)))\n",
    "accuracy = round(accuracy_score(severe_toxic_labels, predictions) *100,2)\n",
    "print(\"Accuracy: \"+str(accuracy))\n",
    "confusion_matrix(severe_toxic_labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "severe_toxic_test = clf.predict_proba(X_test)\n",
    "\n",
    "test_data[\"severe_toxic\"] = pd.Series(severe_toxic_test[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss: 0.05428907765810611\n",
      "Accuracy: 98.14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[151121,      1],\n",
       "       [  2961,   5488]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions for obscene using Random Forest\n",
    "clf = RandomForestClassifier(max_depth=150, n_estimators=100)\n",
    "obscene_labels = list(data[\"obscene\"])\n",
    "clf.fit(X, obscene_labels)\n",
    "ans_probs = clf.predict_proba(X)\n",
    "predictions = clf.predict(X)\n",
    "print(\"Log Loss: \"+str(log_loss(obscene_labels, ans_probs)))\n",
    "accuracy = round(accuracy_score(obscene_labels, predictions) *100,2)\n",
    "print(\"Accuracy: \"+str(accuracy))\n",
    "confusion_matrix(obscene_labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "obscene_test = clf.predict_proba(X_test)\n",
    "\n",
    "test_data[\"obscene\"] = pd.Series(obscene_test[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss: 0.0030608096432204763\n",
      "Accuracy: 99.9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[159090,      3],\n",
       "       [   154,    324]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions for threat using Random Forest\n",
    "clf = RandomForestClassifier(max_depth=150, n_estimators=100)\n",
    "threat_labels = list(data[\"threat\"])\n",
    "clf.fit(X, threat_labels)\n",
    "ans_probs = clf.predict_proba(X)\n",
    "predictions = clf.predict(X)\n",
    "print(\"Log Loss: \"+str(log_loss(threat_labels, ans_probs)))\n",
    "accuracy = round(accuracy_score(threat_labels, predictions) *100,2)\n",
    "print(\"Accuracy: \"+str(accuracy))\n",
    "confusion_matrix(threat_labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "threat_test = clf.predict_proba(X_test)\n",
    "test_data[\"threat\"] = pd.Series(threat_test[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss: 0.060321716314508875\n",
      "Accuracy: 97.75\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[151691,      3],\n",
       "       [  3590,   4287]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions for insult using Random Forest\n",
    "clf = RandomForestClassifier(max_depth=150, n_estimators=100)\n",
    "insult_labels = list(data[\"insult\"])\n",
    "clf.fit(X, insult_labels)\n",
    "ans_probs = clf.predict_proba(X)\n",
    "predictions = clf.predict(X)\n",
    "print(\"Log Loss: \"+str(log_loss(insult_labels, ans_probs)))\n",
    "accuracy = round(accuracy_score(insult_labels, predictions) *100,2)\n",
    "print(\"Accuracy: \"+str(accuracy))\n",
    "confusion_matrix(insult_labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "insult_test = clf.predict_proba(X_test)\n",
    "test_data[\"insult\"] = pd.Series(insult_test[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss: 0.01258264766398848\n",
      "Accuracy: 99.4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[158165,      1],\n",
       "       [   952,    453]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions for identity_hate using Random Forest\n",
    "clf = RandomForestClassifier(max_depth=150, n_estimators=100)\n",
    "identity_hate_labels = list(data[\"identity_hate\"])\n",
    "clf.fit(X, identity_hate_labels)\n",
    "ans_probs = clf.predict_proba(X)\n",
    "predictions = clf.predict(X)\n",
    "print(\"Log Loss: \"+str(log_loss(identity_hate_labels, ans_probs)))\n",
    "accuracy = round(accuracy_score(identity_hate_labels, predictions) *100,2)\n",
    "print(\"Accuracy: \"+str(accuracy))\n",
    "confusion_matrix(identity_hate_labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "identity_hate_test = clf.predict_proba(X_test)\n",
    "test_data[\"identity_hate\"] = pd.Series(identity_hate_test[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_data[\"comment_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.to_csv(\"submission_RF.csv\", index=False) #0.9640 private  0.9658 public"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
